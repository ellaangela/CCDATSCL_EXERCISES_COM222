{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "\n",
        "<img src=\"https://vsqfvsosprmjdktwilrj.supabase.co/storage/v1/object/public/images/insights/1753644539114-netflix.jpeg\"/>\n",
        "\n",
        "\n",
        "In this activity , you will explore two fundamental preprocessing techniques used in data science and machine learning: feature scaling and discretization (binning).\n",
        "\n",
        "These techniques are essential when working with datasets that contain numerical values on very different scales, or continuous variables that may be more useful when grouped into categories.\n",
        "\n",
        "\n",
        "We will use a subset of the Netflix Movies and TV Shows dataset, which contains metadata such as release year, duration, ratings, and other attributes of titles currently or previously available on Netflix. Although the dataset is not originally designed for numerical modeling, it contains several features suitable for preprocessing practice—such as:\n",
        "- Release Year\n",
        "- Duration (in minutes)\n",
        "- Genre\n",
        "\n",
        "In this worksheet, you will:\n",
        "- Load and inspect the dataset\n",
        "- Select numerical features for scaling\n",
        "- Apply different scaling techniques\n",
        "- Min–Max Scaling\n",
        "- Standardization\n",
        "- Robust Scaling\n",
        "- Perform discretization (binning)\n",
        "- Equal-width binning\n",
        "- Equal-frequency binning\n",
        "- Evaluate how scaling affects machine learning performance, using a simple KNN"
      ],
      "metadata": {
        "id": "ibPZ3suCVexv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n"
      ],
      "metadata": {
        "id": "KYfUUuoQQSrU"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Data Loading\n",
        "\n"
      ],
      "metadata": {
        "id": "WvkXboc4QbDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Netflix dataset into a DataFrame named df."
      ],
      "metadata": {
        "id": "Yoc3RS5_Q-P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shivamb/netflix-shows\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "\n",
        "if os.path.isdir(path):\n",
        "  print(True)\n",
        "\n",
        "contents = os.listdir(path)\n",
        "contents\n",
        "\n",
        "mydataset = path + \"/\" + contents[0]\n",
        "mydataset\n",
        "\n",
        "\n",
        "df = pd.read_csv(mydataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BzkIr-IQvc_",
        "outputId": "129d951a-b136-4ab1-b865-0030ee564cb9"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'netflix-shows' dataset.\n",
            "Path to dataset files: /kaggle/input/netflix-shows\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Understanding"
      ],
      "metadata": {
        "id": "gGfX_j85Qvso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the dataset’s column names in a variable called cols."
      ],
      "metadata": {
        "id": "YcLl2A1TRBr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns"
      ],
      "metadata": {
        "id": "Cm9D_TvBRJ49"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the shape of the dataset as a tuple (rows, columns) in shape_info."
      ],
      "metadata": {
        "id": "FICoaiXqRGQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape_info = df.shape"
      ],
      "metadata": {
        "id": "OE00DhX1RGgR"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Cleaning\n",
        "Count missing values per column and save to missing_counts."
      ],
      "metadata": {
        "id": "SpXfo7FbRO_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_counts = df.isnull().sum()"
      ],
      "metadata": {
        "id": "H55Jip9pRPPr"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop rows where duration is missing. Save to df_clean."
      ],
      "metadata": {
        "id": "vgui71afQPWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna(subset=['duration'])"
      ],
      "metadata": {
        "id": "RZoUAN5oRXOG"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Selecting Relevant Numeric Features\n",
        "\n",
        "Many Netflix datasets include numeric fields such as:\n",
        "- release_year\n",
        "- duration\n",
        "- rating\n"
      ],
      "metadata": {
        "id": "ga5goVCWRaO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame `df_num` containing only numeric columns."
      ],
      "metadata": {
        "id": "d8pjbzBIRemP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_num = df_clean.select_dtypes(include='number')"
      ],
      "metadata": {
        "id": "k9K3xPYpTYvf"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Scaling\n",
        "\n",
        "Focus on a single numeric column (e.g., duration).\n"
      ],
      "metadata": {
        "id": "nBnAVv_tTY_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the column duration into a Series named `dur`."
      ],
      "metadata": {
        "id": "aYn7lDiYT8PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's assume, for the purpose of alignment, that one season is approximately equivalent to 500 minutes (e.g., 10 episodes * 50 minutes/episode).\n",
        "\n",
        "df_clean['seasons_in_minutes'] = pd.NA\n",
        "\n",
        "seasons_mask = df_clean['duration'].str.contains('season', case=False, na=False)\n",
        "\n",
        "df_clean.loc[seasons_mask, 'seasons_in_minutes'] = df_clean.loc[seasons_mask, 'duration'].str.extract(r'(\\d+)')[0].astype(int) * 500\n",
        "\n",
        "print(\"Rows with 'seasons_in_minutes' populated:\")\n",
        "print(df_clean[seasons_mask][['duration', 'seasons_in_minutes']].head())"
      ],
      "metadata": {
        "id": "uwsVCCqTTc6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806beb35-6998-4bff-8410-263baedd2556"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with 'seasons_in_minutes' populated:\n",
            "    duration seasons_in_minutes\n",
            "1  2 Seasons               1000\n",
            "2   1 Season                500\n",
            "3   1 Season                500\n",
            "4  2 Seasons               1000\n",
            "5   1 Season                500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1840277760.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean['seasons_in_minutes'] = pd.NA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['minutes_duration_int'] = pd.NA\n",
        "\n",
        "minutes_mask = df_clean['duration'].str.contains('min', case=False, na=False)\n",
        "\n",
        "df_clean.loc[minutes_mask, 'minutes_duration_int'] = df_clean.loc[minutes_mask, 'duration'].str.extract(r'(\\d+)')[0].astype(int)\n",
        "\n",
        "print(\"Rows with 'minutes_duration_int' populated:\")\n",
        "print(df_clean[minutes_mask][['duration', 'minutes_duration_int']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zte8bw2Tzx9P",
        "outputId": "d43245a1-8eff-48b0-e2db-6ef1ba535985"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with 'minutes_duration_int' populated:\n",
            "   duration minutes_duration_int\n",
            "0    90 min                   90\n",
            "6    91 min                   91\n",
            "7   125 min                  125\n",
            "9   104 min                  104\n",
            "12  127 min                  127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1788578889.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean['minutes_duration_int'] = pd.NA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dur = df_clean['minutes_duration_int'].fillna(df_clean['seasons_in_minutes'])\n",
        "\n",
        "print(\"First 5 values of 'dur' Series:\")\n",
        "print(dur.head())\n",
        "print(\"Type of 'dur':\", type(dur))\n",
        "print(\"Number of non-null values in 'dur':\", dur.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lth52XdNzzvb",
        "outputId": "888045d5-d268-4d3d-8f85-9e9b46baaa73"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of 'dur' Series:\n",
            "0      90\n",
            "1    1000\n",
            "2     500\n",
            "3     500\n",
            "4    1000\n",
            "Name: minutes_duration_int, dtype: int64\n",
            "Type of 'dur': <class 'pandas.core.series.Series'>\n",
            "Number of non-null values in 'dur': 8804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1383800932.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dur = df_clean['minutes_duration_int'].fillna(df_clean['seasons_in_minutes'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dur = df_clean['minutes_duration_int'].fillna(df_clean['seasons_in_minutes']).infer_objects(copy=False)\n",
        "\n",
        "print(\"First 5 values of 'dur' Series:\")\n",
        "print(dur.head())\n",
        "print(\"Type of 'dur':\", type(dur))\n",
        "print(\"Number of non-null values in 'dur':\", dur.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw7WVVbUz1RB",
        "outputId": "c8c01156-9e59-4cdd-bd33-9f9102e5ed6b"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of 'dur' Series:\n",
            "0      90\n",
            "1    1000\n",
            "2     500\n",
            "3     500\n",
            "4    1000\n",
            "Name: minutes_duration_int, dtype: int64\n",
            "Type of 'dur': <class 'pandas.core.series.Series'>\n",
            "Number of non-null values in 'dur': 8804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-905736434.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dur = df_clean['minutes_duration_int'].fillna(df_clean['seasons_in_minutes']).infer_objects(copy=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Min–Max Scaling to `dur`. Store the result as `dur_minmax`."
      ],
      "metadata": {
        "id": "coBFKuGUTglp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "dur_minmax = pd.Series(scaler.fit_transform(dur.values.reshape(-1, 1)).flatten(), name='duration_minmax', index=dur.index)\n",
        "\n",
        "print(\"First 5 values of dur_minmax:\")\n",
        "print(dur_minmax.head())\n",
        "print(\"Min value:\", dur_minmax.min())\n",
        "print(\"Max value:\", dur_minmax.max())"
      ],
      "metadata": {
        "id": "IwxkC43JTg6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537e20f3-4e92-4678-9b8d-6f8dbefee054"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of dur_minmax:\n",
            "0    0.010239\n",
            "1    0.117336\n",
            "2    0.058491\n",
            "3    0.058491\n",
            "4    0.117336\n",
            "Name: duration_minmax, dtype: float64\n",
            "Min value: 0.0\n",
            "Max value: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Z-score Standardization to `dur`. Store in `dur_zscore`."
      ],
      "metadata": {
        "id": "eHn5xHNuTk6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "dur_zscore = pd.Series(scaler.fit_transform(dur.values.reshape(-1, 1)).flatten(), name='duration_zscore', index=dur.index)\n",
        "\n",
        "print(\"First 5 values of dur_zscore:\")\n",
        "print(dur_zscore.head())\n",
        "print(\"Mean value (should be close to 0):\", dur_zscore.mean())\n",
        "print(\"Standard deviation (should be close to 1):\", dur_zscore.std())"
      ],
      "metadata": {
        "id": "XNPVErJiTlt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377c4584-c252-4eda-b6fb-d03cea742f5c"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of dur_zscore:\n",
            "0   -0.437240\n",
            "1    1.170126\n",
            "2    0.286958\n",
            "3    0.286958\n",
            "4    1.170126\n",
            "Name: duration_zscore, dtype: float64\n",
            "Mean value (should be close to 0): -3.22827231149523e-18\n",
            "Standard deviation (should be close to 1): 1.0000567972056422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Discretization (Binning)\n",
        "Apply equal-width binning to dur into 5 bins. Store as `dur_width_bins`.\n",
        "\n",
        "\n",
        "- Use `pandas.cut()` to divide duration_minutes into 4 `equal-width bins`.\n",
        "- Add the resulting bins as a new column named:\n",
        "`duration_equal_width_bin`"
      ],
      "metadata": {
        "id": "oatf0dnSTqdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dur_width_bins = pd.cut(dur, bins=5, labels=False, include_lowest=True)\n",
        "\n",
        "df_clean.loc[:, 'duration_equal_width_bin'] = dur_width_bins\n",
        "\n",
        "print(\"First 5 values of dur_width_bins:\")\n",
        "print(dur_width_bins.head())\n",
        "print(\"Bin counts:\")\n",
        "print(dur_width_bins.value_counts().sort_index())"
      ],
      "metadata": {
        "id": "zACIy3YrTp2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cf7ced-aee3-4558-83bf-8e397d28d65e"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of dur_width_bins:\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: minutes_duration_int, dtype: int64\n",
            "Bin counts:\n",
            "minutes_duration_int\n",
            "0    8545\n",
            "1     193\n",
            "2      56\n",
            "3       7\n",
            "4       3\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3300242895.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean.loc[:, 'duration_equal_width_bin'] = dur_width_bins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the characteristics of each bin\n",
        "\n",
        "- What are the bin edges produced by equal-width binning?\n",
        "- How many movies fall into each bin?"
      ],
      "metadata": {
        "id": "_BXKOqU0XbE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bin edges (Intervals) and counts:\")\n",
        "print(bins_info.value_counts().sort_index())\n",
        "\n",
        "print(\"\\nExplicit bin edges:\")\n",
        "for i, interval in enumerate(unique_bins):\n",
        "    print(f\"Bin {i}: {interval.left:.2f} to {interval.right:.2f}\")"
      ],
      "metadata": {
        "id": "hh4vr2JrXejO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0601f5e6-5108-4fe2-e65b-72161a5187fa"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin edges (Intervals) and counts:\n",
            "minutes_duration_int\n",
            "(-5.498, 1702.4]    8545\n",
            "(1702.4, 3401.8]     193\n",
            "(3401.8, 5101.2]      56\n",
            "(5101.2, 6800.6]       7\n",
            "(6800.6, 8500.0]       3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Explicit bin edges:\n",
            "Bin 0: -5.50 to 1702.40\n",
            "Bin 1: 1702.40 to 3401.80\n",
            "Bin 2: 3401.80 to 5101.20\n",
            "Bin 3: 5101.20 to 6800.60\n",
            "Bin 4: 6800.60 to 8500.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply equal-frequency binning to dur into 5 bins. Store as `dur_quantile_bins`.\n",
        "\n",
        "- Use `pandas.qcut()` to divide duration_minutes into 4 equal-frequency bins.\n",
        "- Add the result as a new column named:\n",
        "`duration_equal_freq_bin`"
      ],
      "metadata": {
        "id": "bmYxVCxHUBDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_quantile_bins = pd.qcut(dur, q=5, labels=False, duplicates='drop')\n",
        "\n",
        "df_clean = df_clean.copy()\n",
        "df_clean.loc[:, 'duration_equal_freq_bin'] = dur_quantile_bins\n",
        "\n",
        "print(\"First 5 values of dur_quantile_bins:\")\n",
        "print(dur_quantile_bins.head())\n",
        "print(\"Bin counts:\")\n",
        "print(dur_quantile_bins.value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SaJxGqC3J2d",
        "outputId": "0a8f2e27-3cfd-48c9-d267-8a483172d89a"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of dur_quantile_bins:\n",
            "0    1\n",
            "1    4\n",
            "2    3\n",
            "3    3\n",
            "4    4\n",
            "Name: minutes_duration_int, dtype: int64\n",
            "Bin counts:\n",
            "minutes_duration_int\n",
            "0    1838\n",
            "1    1714\n",
            "2    1757\n",
            "3    2612\n",
            "4     883\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the characteristics of each bin\n",
        "\n",
        "- What are the bin ranges produced by equal-frequency binning?\n",
        "- How many movies fall into each bin? Are they nearly equal?"
      ],
      "metadata": {
        "id": "DbI8tlqZXhl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bins_info_qcut = pd.qcut(dur, q=5, duplicates='drop')\n",
        "\n",
        "print(\"Bin ranges (Intervals) and counts:\")\n",
        "print(bins_info_qcut.value_counts().sort_index())\n",
        "\n",
        "print(\"\\nAre the bin counts nearly equal? A perfect equal-frequency binning would have each bin containing approximately 8804 / 5 = 1760.8 entries.\")\n",
        "print(\"The counts are: \", bins_info_qcut.value_counts().sort_index().values)\n"
      ],
      "metadata": {
        "id": "Vg-_EbXwXjtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9414e7e2-81c4-41ea-9136-32b0922b94b5"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin ranges (Intervals) and counts:\n",
            "minutes_duration_int\n",
            "(2.999, 89.0]      1838\n",
            "(89.0, 102.0]      1714\n",
            "(102.0, 127.0]     1757\n",
            "(127.0, 500.0]     2612\n",
            "(500.0, 8500.0]     883\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Are the bin counts nearly equal? A perfect equal-frequency binning would have each bin containing approximately 8804 / 5 = 1760.8 entries.\n",
            "The counts are:  [1838 1714 1757 2612  883]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. KNN Before & After Scaling\n"
      ],
      "metadata": {
        "id": "UKcTGeFuUGCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a feature matrix X using any two numeric columns and a target y (e.g., classification by genre or type). Create a train/test split."
      ],
      "metadata": {
        "id": "UCtoN-PgUNoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame({\n",
        "    'release_year': df_clean['release_year'],\n",
        "    'duration': dur\n",
        "})\n",
        "y = df_clean['type']\n",
        "\n",
        "print(\"First 5 rows of X:\")\n",
        "print(X.head())\n",
        "print(\"\\nFirst 5 values of y:\")\n",
        "print(y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL5fSID13rhk",
        "outputId": "8cd50513-1ef1-4d51-f786-0b5beaacd046"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of X:\n",
            "   release_year  duration\n",
            "0          2020        90\n",
            "1          2021      1000\n",
            "2          2021       500\n",
            "3          2021       500\n",
            "4          2021      1000\n",
            "\n",
            "First 5 values of y:\n",
            "0      Movie\n",
            "1    TV Show\n",
            "2    TV Show\n",
            "3    TV Show\n",
            "4    TV Show\n",
            "Name: type, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a KNN classifier without scaling. Store accuracy in acc_raw."
      ],
      "metadata": {
        "id": "AmUQOtuRUUIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred_raw = knn.predict(X_test)\n",
        "\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "print(f\"Accuracy of KNN on raw data: {acc_raw:.4f}\")"
      ],
      "metadata": {
        "id": "orTC6sHmUXGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb398c2d-136b-4aa7-8b14-107dabf80ff3"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN on raw data: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale `X` using either Min–Max or Standardization, retrain KNN, and store accuracy in acc_scaled."
      ],
      "metadata": {
        "id": "AdyOwTF9UXcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn_scaled.fit(X_train_scaled_df, y_train)\n",
        "\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled_df)\n",
        "\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy of KNN on scaled data: {acc_scaled:.4f}\")"
      ],
      "metadata": {
        "id": "TjAp_3_4UX3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbeca097-ea69-4df0-ff88-d57d32ab5fbf"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN on scaled data: 0.9989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did scaling improve accuracy? Explain why."
      ],
      "metadata": {
        "id": "BBide7G7UhK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison between KNN with and without scaling shows that the raw model achieved an accuracy of 1.0000, while the scaled version using StandardScaler slightly decreased to 0.9989. This result is unusual because scaling typically improves KNN performance, especially when features have very different ranges. KNN is a distance-based algorithm, and features with larger numerical scales tend to dominate the distance calculation. In this dataset, duration has a much larger range (reaching up to thousands of minutes for TV shows) compared to release_year, which spans only about a century. The extremely high unscaled accuracy suggests that duration alone was strong enough to separate movies from TV shows because these two categories differ significantly in typical duration. As a result, KNN relied almost entirely on the unscaled duration feature, producing a perfect score. After scaling, both duration and release_year were given equal influence in the distance computation. However, release_year does not meaningfully distinguish between the two classes, so giving it equal weight introduced weakly relevant information. This slightly reduced the model's accuracy compared to when duration was allowed to dominate the decision.\n"
      ],
      "metadata": {
        "id": "xhhlLsSl5sdS"
      }
    }
  ]
}